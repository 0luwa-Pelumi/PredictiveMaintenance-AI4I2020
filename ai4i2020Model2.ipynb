{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f91d6812-c479-40b8-9778-f68b180633b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary information about the DataFrame including data types and non-null values\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   UID                      10000 non-null  int64  \n",
      " 1   Product ID               10000 non-null  object \n",
      " 2   Type                     10000 non-null  object \n",
      " 3   Air temperature [K]      10000 non-null  float64\n",
      " 4   Process temperature [K]  10000 non-null  float64\n",
      " 5   Rotational speed [rpm]   10000 non-null  int64  \n",
      " 6   Torque [Nm]              10000 non-null  float64\n",
      " 7   Tool wear [min]          10000 non-null  int64  \n",
      " 8   Machine failure          10000 non-null  int64  \n",
      " 9   TWF                      10000 non-null  int64  \n",
      " 10  HDF                      10000 non-null  int64  \n",
      " 11  PWF                      10000 non-null  int64  \n",
      " 12  OSF                      10000 non-null  int64  \n",
      " 13  RNF                      10000 non-null  int64  \n",
      "dtypes: float64(3), int64(9), object(2)\n",
      "memory usage: 1.1+ MB\n",
      "None\n",
      "information about the engineered features dataset:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 19 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   UID                      10000 non-null  int64  \n",
      " 1   Product ID               10000 non-null  object \n",
      " 2   Type                     10000 non-null  object \n",
      " 3   Air temperature [K]      10000 non-null  float64\n",
      " 4   Process temperature [K]  10000 non-null  float64\n",
      " 5   Rotational speed [rpm]   10000 non-null  int64  \n",
      " 6   Torque [Nm]              10000 non-null  float64\n",
      " 7   Tool wear [min]          10000 non-null  int64  \n",
      " 8   Machine failure          10000 non-null  int64  \n",
      " 9   TWF                      10000 non-null  int64  \n",
      " 10  HDF                      10000 non-null  int64  \n",
      " 11  PWF                      10000 non-null  int64  \n",
      " 12  OSF                      10000 non-null  int64  \n",
      " 13  RNF                      10000 non-null  int64  \n",
      " 14  Temp_diff                10000 non-null  float64\n",
      " 15  Power [W]                10000 non-null  float64\n",
      " 16  Wear_Torque              10000 non-null  float64\n",
      " 17  TWF_risk                 10000 non-null  int32  \n",
      " 18  OSF_risk                 10000 non-null  int64  \n",
      "dtypes: float64(6), int32(1), int64(10), object(2)\n",
      "memory usage: 1.4+ MB\n",
      "None\n",
      "\n",
      "Encode Data(\"Type Categories\"): \n",
      "      Type_H  Type_L  Type_M\n",
      "0        0.0     0.0     1.0\n",
      "1        0.0     1.0     0.0\n",
      "2        0.0     1.0     0.0\n",
      "3        0.0     1.0     0.0\n",
      "4        0.0     1.0     0.0\n",
      "...      ...     ...     ...\n",
      "9995     0.0     0.0     1.0\n",
      "9996     1.0     0.0     0.0\n",
      "9997     0.0     0.0     1.0\n",
      "9998     1.0     0.0     0.0\n",
      "9999     0.0     0.0     1.0\n",
      "\n",
      "[10000 rows x 3 columns]\n",
      "\n",
      "Number of Machine failure in the dataset: 339\n",
      "\n",
      "Shapes of the training and testing sets to verify the split\n",
      "Features - Test: (2000, 18), Train: (8000, 18)\n",
      "Target - Test: (2000,), Train: (8000,)\n",
      "\n",
      "class distribution before and after resampling\n",
      "Before SMOTE: Machine failure\n",
      "0    7729\n",
      "1     271\n",
      "Name: count, dtype: int64\n",
      "After SMOTE: Machine failure\n",
      "0    7729\n",
      "1    3864\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== RandomForest Results (Clean) ===\n",
      "Accuracy: 0.996\n",
      "roc_auc_score: 0.977\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1927    5]\n",
      " [   3   65]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1932\n",
      "           1       0.93      0.96      0.94        68\n",
      "\n",
      "    accuracy                           1.00      2000\n",
      "   macro avg       0.96      0.98      0.97      2000\n",
      "weighted avg       1.00      1.00      1.00      2000\n",
      "\n",
      "\n",
      "Model is saved as: ai4i2020_rfc_M2.pkl \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "# Define the file path to the dataset\n",
    "# This path points to a CSV file named 'ai4i2020.csv' located on the desktop\n",
    "path = r\"C:\\Users\\PC\\Desktop\\Ai4i2020\\ai4i2020.csv\"\n",
    "\n",
    "# Load the dataset from the specified path into a pandas DataFrame named 'ai4i'\n",
    "ai4i = pd.read_csv(path)\n",
    "# Display summary information about the DataFrame including data types and non-null values\n",
    "print(\"Summary information about the DataFrame including data types and non-null values\\n\")\n",
    "print(ai4i.info())\n",
    "\n",
    "#features engineering \n",
    "\n",
    "def engineer_features(df):\n",
    "     # Calculate temperature difference between process and air temperature\n",
    "    df['Temp_diff'] = df['Process temperature [K]'] - df['Air temperature [K]']\n",
    "    # Calculate power in Watts using torque and rotational speed (P = T * ω)\n",
    "    # Convert rpm to radians/second by multiplying by 2π/60\n",
    "    df['Power [W]'] = df['Torque [Nm]'] * df['Rotational speed [rpm]'] * (2 * np.pi / 60)\n",
    "    df['Wear_Torque'] = df['Tool wear [min]'] * df['Torque [Nm]']\n",
    "    # Create binary feature for Tool Wear Failure risk\n",
    "    # Risk is present when tool wear is between 200-240 minutes\n",
    "    df['TWF_risk'] = ((df['Tool wear [min]'] >= 200) & (df['Tool wear [min]'] <= 240)).astype(int)\n",
    "    \n",
    "    # Initialize Overstrain Failure risk feature\n",
    "    df['OSF_risk'] = 0\n",
    "    # Set OSF risk based on product type and Wear_Torque threshold\n",
    "    # Different thresholds for different product types (L, M, H)\n",
    "    df.loc[(df['Type'] == 'L') & (df['Wear_Torque'] > 11000), 'OSF_risk'] = 1\n",
    "    df.loc[(df['Type'] == 'M') & (df['Wear_Torque'] > 12000), 'OSF_risk'] = 1\n",
    "    df.loc[(df['Type'] == 'H') & (df['Wear_Torque'] > 13000), 'OSF_risk'] = 1\n",
    "\n",
    "    return df\n",
    "\n",
    "ai4i_X_eFeatures = engineer_features(ai4i)\n",
    "# Display information about the engineered features dataset\n",
    "# This shows the column names, non-null counts, and data types\n",
    "print(f\"information about the engineered features dataset:\\n\")\n",
    "print(ai4i_X_eFeatures.info())\n",
    "\n",
    "# Create an encoder that:\n",
    "# - handles unknown categories by ignoring them\n",
    "# - returns dense arrays instead of sparse matrices\n",
    "# - outputs pandas DataFrames instead of numpy arrays\n",
    "encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False).set_output(transform=\"pandas\")\n",
    "\n",
    "# Apply one-hot encoding to the \"Type\" column in the dataset\n",
    "# This transforms categorical values into binary columns (one for each category)\n",
    "enc = encoder.fit_transform(ai4i_X_eFeatures[[\"Type\"]])\n",
    "\n",
    "# Display the encoded data\n",
    "print(f'\\nEncode Data(\"Type Categories\"): \\n{enc}')\n",
    "\n",
    "# Concatenate engineered features with one-hot encoded 'Type' column and remove original 'Type' column\n",
    "ai4i_X_eFeatures = pd.concat([ai4i_X_eFeatures,enc],axis=1).drop(columns=\"Type\")\n",
    "ai4i_X_eFeatures.columns\n",
    "\n",
    "# Define list of features to be used for modeling\n",
    "features = [\n",
    "    'Air temperature [K]',          # Raw sensor measurement of air temperature\n",
    "    'Process temperature [K]',      # Raw sensor measurement of process temperature\n",
    "    'Rotational speed [rpm]',       # Raw sensor measurement of rotational speed\n",
    "    'Torque [Nm]',                  # Raw sensor measurement of torque\n",
    "    'Tool wear [min]',              # Raw measurement of tool wear time\n",
    "    'TWF', 'HDF', 'PWF', 'OSF', 'RNF',  # Failure type indicators (binary)\n",
    "    'Temp_diff',                    # Engineered feature: temperature difference\n",
    "    'Power [W]',                    # Engineered feature: calculated power\n",
    "    'Wear_Torque',                  # Engineered feature: relationship between wear and torque\n",
    "    'TWF_risk',                     # Engineered feature: TWF risk indicator\n",
    "    'OSF_risk',                     # Engineered feature: OSF risk indicator\n",
    "    'Type_H', 'Type_L','Type_M'     # One-hot encoded machine type features\n",
    "]\n",
    "\n",
    "# Define target variable for prediction\n",
    "target = 'Machine failure'\n",
    "\n",
    "# Count the number of machine failures in the dataset\n",
    "machine_failure_count= (ai4i_X_eFeatures[\"Machine failure\"]== 1).sum()\n",
    "print(f\"\\nNumber of Machine failure in the dataset: {machine_failure_count}\")\n",
    "\n",
    "# Extract the feature columns from the dataset for model training\n",
    "X = ai4i_X_eFeatures[features]\n",
    "\n",
    "# Extract the target variable (machine failure) for model training\n",
    "y = ai4i_X_eFeatures[target]\n",
    "\n",
    "# Split the dataset into training (80%) and testing (20%) sets\n",
    "# stratify=y ensures that the class distribution in the splits matches the original dataset\n",
    "# random_state=12 ensures reproducibility of the split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=12)\n",
    "\n",
    "# Print the shapes of the training and testing sets to verify the split\n",
    "print(\"\\nShapes of the training and testing sets to verify the split\")\n",
    "print(f\"Features - Test: {X_test.shape}, Train: {X_train.shape}\")\n",
    "print(f\"Target - Test: {y_test.shape}, Train: {y_train.shape}\")\n",
    "\n",
    "\n",
    "# Initialize SMOTE with sampling_strategy=0.5 (minority class will be resampled to 50% of majority class)\n",
    "# random_state ensures reproducibility of results\n",
    "smote = SMOTE(sampling_strategy=0.5, random_state=12)\n",
    "\n",
    "# Apply SMOTE to training data\n",
    "# This creates synthetic samples for the minority class\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"\\nclass distribution before and after resampling\")\n",
    "# Display class distribution before applying SMOTE\n",
    "print(\"Before SMOTE:\", y_train.value_counts())\n",
    "# Display class distribution after applying SMOTE\n",
    "# Should show more balanced classes compared to before\n",
    "print(\"After SMOTE:\", y_train_resampled.value_counts())\n",
    "\n",
    "# Initialize a Random Forest Classifier with:\n",
    "# - 200 decision trees (n_estimators)\n",
    "# - balanced class weights to handle imbalanced data\n",
    "# - maximum tree depth of 10 to prevent overfitting\n",
    "# - random state of 12 for reproducibility\n",
    "model = RandomForestClassifier(n_estimators= 200, class_weight=\"balanced\", max_depth=10, random_state=12)\n",
    "\n",
    "# Train the model on the resampled training data\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "print(\"\\n=== RandomForest Results (Clean) ===\")\n",
    "# Calculate and display accuracy\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc:.3f}\")\n",
    "\n",
    "# Calculate and display ROC AUC \n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print(f\"roc_auc_score: {(auc):.3f}\")\n",
    "\n",
    "# Display confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Display detailed classification metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "# Prepare model data for saving (includes model and feature information)\n",
    "model_data={\n",
    "    \"model\" : model,\n",
    "    \"features_order\" : X_train.columns.tolist(),\n",
    "    \"features_types\" : X_train.dtypes.to_dict()\n",
    "}\n",
    "# Save model to disk\n",
    "joblib.dump(model_data, \"ai4i2020_rfc_M2.plk\")\n",
    "# Confirm model has been saved\n",
    "print(\"\\nModel is saved as: ai4i2020_rfc_M2.pkl \")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e66851-4113-455d-ae92-10664ddf7112",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
